{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empirical Dynamic Modeling via Machine Learning\n",
    "\n",
    "*Kevin Siswandi*, 23 September 2020.\n",
    "\n",
    "Typically the dynamics is described by some nonlinear ODE:\n",
    "\n",
    "$$ \\dot{x}(t) = f(x(t)) $$\n",
    "\n",
    "Bottom-up modeling example:\n",
    "\n",
    "$$\\begin{split} \\dot{x_1} & = 2 k_1 x_1 x_2 -  \\frac{k_p x_1}{x_1 + K_m} \\\\\n",
    "\\dot{x_2} & = V_{in} - k_1 x_2 x_1\n",
    "\\end{split}$$\n",
    "\n",
    "2-D Model of Yeast Glycolysis from *Bier, Bakker, & Westerhoff (Biophys. J. 78:1087-1093, 2000)*.\n",
    "\n",
    "$$ x(t) = x(t_0) + \\int_{t_0}^{t} f(x(t')) \\,d{t'} $$ \n",
    "\n",
    "Data-driven modeling: given time-series measurements\n",
    "\n",
    "$$\\{x(t_n)\\},$$\n",
    "\n",
    "create pairs of training data\n",
    "\n",
    "$$\\dot{x}(t_i), x(t_i)$$\n",
    "\n",
    "as pairs of target-features, for every time point $i = 1,.., n$. This gives us a supervised learning problem:\n",
    "\n",
    "$$ \\arg \\min_f \\sum_{i=0}^n || f(x(t_i)) - \\dot{x}(t_i)||^2 $$\n",
    "\n",
    "that is solved to find the function $f$ that best describes the data through a machine learning method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Direction\n",
    "\n",
    "Traditional Supervised Learning problem:\n",
    "$$ f: X \\rightarrow Y$$\n",
    "X are the features, Y are the targets. In our case, we learn $f'$ instead. Two approaches:\n",
    "1. Manually compute derivatives from time-series data.\n",
    "2. Embed the supervised learning problem in the framework of multistep method.\n",
    "\n",
    "Performance metric:\n",
    "1. Wasserstein Distance\n",
    "2. Dynamic Time Warping\n",
    "3. Kullback-Leibler Divergence\n",
    "\n",
    "Wasserstein Distance takes into account the metric space!\n",
    "\n",
    "![](https://i.stack.imgur.com/7rxeM.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Pathway Dynamics using Machine Learning\n",
    "\n",
    "In the first half of the project, we use experimental data from proteomics and metabolomics to predict the metabolic pathway dynamics of either limonene or isopentenol produced by Escherichia Coli strains. In bioengineering, we often want to predict the cell behavior that results from the engineered changes in DNA. This is made possible thanks to the recent technological advances:\n",
    "1. new synthetic biology capabilities, such as the gene-editing tool CRISPR-Cas9,\n",
    "2. Availability of proteomics and metabolomics data\n",
    "\n",
    "Turning these data into actionable insights is not trivial. While stoichiometric models ignore enzyme kinetics and cannot accurately capture the dynamics, kinetic models also have limitations:\n",
    "* the kinetic parameters are estimated from in-vitro measurements which may not be valid in in-vivo conditions/experiments\n",
    "* knowledge of the kinetic rate law for each specific reaction is required.\n",
    "\n",
    "On the other hand, an ML approach could be automatically applied to any new pathway, improve in accuracy with more training data, and help in capturing complex dynamic relationships that are otherwise unknown. It also enables faster development of predictive pathway dynamics since all required knowledge is inferred from the experimental data.\n",
    "\n",
    "The first step is to join the metabolites and protein tables, while creating the training data set consisting of:\n",
    "* smoothed features (using [Savitzky-Golay](https://scipy-cookbook.readthedocs.io/items/SavitzkyGolay.html) low-pass filter)\n",
    "* targets obtained by taking the derivative of the interpolated (smoothed) measurements\n",
    "\n",
    "Here we will use TPOT to automate the ML pipeline: https://github.com/EpistasisLab/tpot. Cross-validation with learning curve is used to compare pipelines. For an interpretation of the learning curve, see: https://scikit-learn.org/stable/modules/learning_curve.html#learning-curve\n",
    "\n",
    "## Applications\n",
    "\n",
    "Remarks: Limonene is a bio-based jet fuel while isopentenol is a gasoline replacement.\n",
    "\n",
    "* Accelerate the design of microbes/pathways that produce biofuel\n",
    "* Provide a new way to guide bioengineering efforts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LmmNet\n",
    "\n",
    "In Multistep Neural Network, training is done to find the optimal parameters via minimising loss function:\n",
    "\n",
    "$$ \\arg \\min_w \\frac{1}{N - M + 1} \\sum_{n = M}^{N} |\\textbf{y}_n|^2 $$\n",
    "\n",
    "where N is the number of data points and M multi steps. The linear difference/residual operator is defined as\n",
    "\n",
    "$$ \\textbf{y}_n = \\sum_{n=0}^M \\left(\\alpha_m x_{n-m} + h \\beta_m \\textbf{f}(\\textbf{x}_{n-m}) \\right)$$\n",
    "\n",
    "for $n=M,...,N$. Now, which step size to use is problem-dependent and hence needs to be tuned for performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive Summary\n",
    "\n",
    "1. One-step learning method $\\rightarrow$ learn dynamics by computing derivatives from time-series data, then solve the optimization problem through machine learning methods. (No assumption of governing equations).\n",
    "$$ \\dot{x} = f(x, u) $$\n",
    "2. LmmNet $\\rightarrow$ learn dynamics by embedding a supervised learning problem inside a linear multistep method. This method assumes highly idealized setting where the data points are sampled at regular intervals. This issue can be overcome by using a 'data augmentation' strategy.\n",
    "\n",
    "We evaluate thhe one-step method and the LmmNet extensively on canonical systems and also complex biochemical problems.\n",
    "\n",
    "## Harmonic Oscillator\n",
    "\n",
    "* 2-D Linear Oscillator\n",
    "* We evaluate the performance of both methods on test data of the harmonic oscillator with cubic dynamics.\n",
    "* With increasing augmentation, we get better performance.\n",
    "\n",
    "## Linear Oscillator\n",
    "\n",
    "* 3-D Linear Oscillator\n",
    "* Evaluate the performance\n",
    "* DTW, Wasserstein, MSE\n",
    "* With increasing augmentation, we get better performance.\n",
    "\n",
    "## Lorenz System\n",
    "\n",
    "* We show that our methods accurately identify the attractor dynamics.\n",
    "* 3-dimensional\n",
    "\n",
    "## Hopf Bifurcation\n",
    "\n",
    "* We show that our methods can identify bifurcation\n",
    "* 3-dimensional\n",
    "\n",
    "## 2-D Glycolysis\n",
    "\n",
    "* We show that by training on two time-series, we can have 'very good' predictions on the test data.\n",
    "* 2-D\n",
    "\n",
    "## Cell Cycle\n",
    "\n",
    "* The performance (accuracy) of both LmmNet and one-step learning improves with more data\n",
    "* We also find that the methods are able to identify the dynamics of the 7 biochemical species.\n",
    "* Simulate the results from Tyson and experiments from Solomon. (the S-shaped) MPF-cyclin curve.\n",
    "* 1993\n",
    "\n",
    "## Metabolic Pathway in E. Coli\n",
    "\n",
    "* We do this using LmmNet (first test of LmmNet on real data)\n",
    "* Extracting mechanistic insights using post-hoc explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
